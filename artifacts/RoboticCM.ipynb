{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Train, Deploy RoboticCM with AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-robotic-cm-bot/training-data.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='sagemaker-robotic-cm-bot'\n",
    "prefix = 'linear-svc' # Used as part of the path in the bucket where you store data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket) # The URL to access the bucket\n",
    "\n",
    "raw_pipe_line_data = 's3://{}/{}'.format(bucket, 'training-data.csv') \n",
    "\n",
    "print(raw_pipe_line_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roboticcm = pd.read_csv(raw_pipe_line_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = roboticcm.drop('Sussessful', 1) # the name of result field.\n",
    "labels = roboticcm['Sussessful'] # *** he name of result field.\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'F453412BCFB44309',\n",
       "  'HostId': 'aF42vDHkYEhxNb9kLWSqV9na6gH6NZ3J3PjfHY1mpRGrNCJ4IlYehlglPwkhQfvSwyD94Md1SQA=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'aF42vDHkYEhxNb9kLWSqV9na6gH6NZ3J3PjfHY1mpRGrNCJ4IlYehlglPwkhQfvSwyD94Md1SQA=',\n",
       "   'x-amz-request-id': 'F453412BCFB44309',\n",
       "   'date': 'Tue, 09 Jun 2020 15:13:08 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"358ba71f4f7d47d9334fa083f1349227\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"358ba71f4f7d47d9334fa083f1349227\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "test_csv_buffer = StringIO()\n",
    "train_csv_buffer = StringIO()\n",
    "pd.concat([test_labels, test], axis=1).to_csv(test_csv_buffer, header=True, index=False)\n",
    "pd.concat([train_labels, train], axis=1).to_csv(train_csv_buffer, header=True, index=False)\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, prefix + '/train.csv').put(Body=train_csv_buffer.getvalue())\n",
    "s3_resource.Object(bucket, prefix + '/validation.csv').put(Body=test_csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 's3://{}/{}/{}'.format(bucket, prefix, 'train.csv')\n",
    "\n",
    "validation_data = 's3://{}/{}/{}'.format(bucket, prefix, 'validation.csv')\n",
    "\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model_sdk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         train_volume_size = 5,\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.set_hyperparameters(max_depth = 5,\n",
    "                              eta = .2,\n",
    "                              gamma = 4,\n",
    "                              min_child_weight = 6,\n",
    "                              silent = 0,\n",
    "                              objective = 'multi:softmax',\n",
    "                              num_class = 2,\n",
    "                              num_round = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.session.s3_input(train_data, content_type='text/csv')\n",
    "valid_channel = sagemaker.session.s3_input(validation_data, content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': valid_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 15:13:21 Starting - Starting the training job...\n",
      "2020-06-09 15:13:23 Starting - Launching requested ML instances......\n",
      "2020-06-09 15:14:42 Starting - Preparing the instances for training......\n",
      "2020-06-09 15:15:43 Downloading - Downloading input data...\n",
      "2020-06-09 15:16:12 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value multi:softmax to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:16:34] 1136x12 matrix with 13632 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:16:34] 561x12 matrix with 6732 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 1136 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 561 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.00088#011validation-merror:0.001783\u001b[0m\n",
      "\n",
      "2020-06-09 15:16:44 Uploading - Uploading generated training model\n",
      "2020-06-09 15:16:44 Completed - Training job completed\n",
      "Training seconds: 61\n",
      "Billable seconds: 61\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(inputs=data_channels,  logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Endpoint\n",
    "\n",
    "And with our model created and our model artifacts in S3, we can deploy our model. The Sagemaker SDK makes this incredibly easy for us. Sagemaker will create the model, endpoint configuration, as well as the endpoint, which are all hosted within Sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                                instance_type='ml.t2.medium',\n",
    "                                endpoint_name='change-success-predictor'\n",
    "                                ) # *** change the name of the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

